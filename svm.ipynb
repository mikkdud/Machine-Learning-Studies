{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3a4b9eee",
      "metadata": {
        "id": "3a4b9eee"
      },
      "source": [
        "# Klasyfikacja i regresja z wykorzystaniem SVM (Support Vector Machines)\n",
        "\n",
        "W tym laboratorium wykorzystujemy **SVM** do dwóch zadań:\n",
        "- **klasyfikacja** (zbiory *Breast Cancer* i *Iris*),\n",
        "- **regresja** (dane syntetyczne).\n",
        "\n",
        "### Czym jest SVM?\n",
        "**Support Vector Machines** to rodzina modeli uczących się granicy decyzyjnej (hiperpłaszczyzny) z **maksymalnym marginesem** względem najbliższych punktów (tzw. *wektorów nośnych*).\n",
        "\n",
        "- W **klasyfikacji** dążymy do rozdzielenia klas możliwie szerokim marginesem (z ewentualnymi błędami kontrolowanymi przez parametr **C**).\n",
        "- W **regresji** (SVR) modeluje się funkcję, dla której błąd mniejszy niż **ε (epsilon)** nie jest karany – powstaje tzw. *epsilon-insensitive tube*.\n",
        "\n",
        "### Dlaczego skalowanie cech jest ważne?\n",
        "SVM (zwłaszcza liniowe) są **wrażliwe na skalę** – cecha o większej skali może zdominować funkcję decyzyjną. Dlatego często stosujemy **Standaryzację** (`StandardScaler`) przed `LinearSVC`/`SVR`.\n",
        "\n",
        "### Kernele\n",
        "SVM może działać w oryginalnej przestrzeni cech (**kernel liniowy**) lub w przestrzeniach cech po nieliniowych mapowaniach – dzięki trikom jądrowym (**polynomial**, **RBF** itd.).\n",
        "W tym notatniku porównujemy m.in.:\n",
        "- `LinearSVC` z/bez standaryzacji,\n",
        "- `LinearSVR` bez i z ekspansją cech (wielomian + standaryzacja),\n",
        "- `SVR(kernel='poly')` oraz jego strojenie hiperparametrów siatką.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ed96468",
      "metadata": {
        "id": "4ed96468"
      },
      "source": [
        "## Sekcja 1 — Klasyfikacja: Breast Cancer (z i bez skalowania)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d376ba5d",
      "metadata": {
        "id": "d376ba5d"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn import datasets\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Dane: Breast Cancer\n",
        "data_breast_cancer = datasets.load_breast_cancer(as_frame=True)\n",
        "X_br = data_breast_cancer['data'][['mean area', 'mean smoothness']]\n",
        "y_br = data_breast_cancer['target']\n",
        "\n",
        "X_br_train, X_br_test, y_br_train, y_br_test = train_test_split(X_br, y_br, test_size=0.2, random_state=42, stratify=y_br)\n",
        "\n",
        "# Pipeline bez skalowania\n",
        "svm_clf_br_noscaling = Pipeline([\n",
        "    (\"linear_svc\", LinearSVC(C=1, loss=\"hinge\", random_state=42, max_iter=10000))\n",
        "])\n",
        "svm_clf_br_noscaling.fit(X_br_train, y_br_train)\n",
        "\n",
        "# Pipeline ze skalowaniem\n",
        "svm_clf_br_scaling = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"linear_svc\", LinearSVC(C=1, loss=\"hinge\", random_state=42, max_iter=10000))\n",
        "])\n",
        "svm_clf_br_scaling.fit(X_br_train, y_br_train)\n",
        "\n",
        "# Ocena — zbiory treningowe i testowe\n",
        "y_br_train_pred_noscaling = svm_clf_br_noscaling.predict(X_br_train)\n",
        "y_br_train_pred_scaling  = svm_clf_br_scaling.predict(X_br_train)\n",
        "acc_br_train_noscaling = accuracy_score(y_br_train, y_br_train_pred_noscaling)\n",
        "acc_br_train_scaling   = accuracy_score(y_br_train, y_br_train_pred_scaling)\n",
        "\n",
        "y_br_test_pred_noscaling = svm_clf_br_noscaling.predict(X_br_test)\n",
        "y_br_test_pred_scaling  = svm_clf_br_scaling.predict(X_br_test)\n",
        "acc_br_test_noscaling = accuracy_score(y_br_test, y_br_test_pred_noscaling)\n",
        "acc_br_test_scaling   = accuracy_score(y_br_test, y_br_test_pred_scaling)\n",
        "\n",
        "print(\"Breast Cancer — accuracy:\")\n",
        "print(\"train (no scaling):\", acc_br_train_noscaling)\n",
        "print(\"train (with scaling):\", acc_br_train_scaling)\n",
        "print(\"test  (no scaling):\", acc_br_test_noscaling)\n",
        "print(\"test  (with scaling):\", acc_br_test_scaling)\n",
        "\n",
        "# Prosta wizualizacja punktów oraz predykcji modelu ze skalowaniem (na zbiorze treningowym)\n",
        "plt.figure()\n",
        "plt.scatter(X_br_train['mean area'], X_br_train['mean smoothness'])\n",
        "plt.title(\"Breast Cancer — dane treningowe (2 cechy)\")\n",
        "plt.xlabel(\"mean area\")\n",
        "plt.ylabel(\"mean smoothness\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.scatter(X_br_train['mean area'], X_br_train['mean smoothness'])\n",
        "plt.title(\"Breast Cancer — ta sama chmura; kolorowanie predykcją nie ustawione (wymagałoby siatki)\")\n",
        "plt.xlabel(\"mean area\")\n",
        "plt.ylabel(\"mean smoothness\")\n",
        "plt.show()\n",
        "\n",
        "# Zapis wyników\n",
        "import pickle\n",
        "br_results = (acc_br_train_noscaling, acc_br_test_noscaling, acc_br_train_scaling, acc_br_test_scaling)\n",
        "with open(\"bc_acc.pkl\", \"wb\") as f:\n",
        "    pickle.dump(br_results, f)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79eb5855",
      "metadata": {
        "id": "79eb5855"
      },
      "source": [
        "## Sekcja 2 — Klasyfikacja: Iris (z i bez skalowania)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab511943",
      "metadata": {
        "id": "ab511943"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Dane: Iris — binaryzacja: Virginica (2) vs. reszta\n",
        "data_iris = datasets.load_iris(as_frame=True)\n",
        "X_iris = data_iris['data'][['petal length (cm)', 'petal width (cm)']]\n",
        "y_iris = (data_iris['target'] == 2)\n",
        "\n",
        "X_iris_train, X_iris_test, y_iris_train, y_iris_test = train_test_split(X_iris, y_iris, test_size=0.2, random_state=42, stratify=y_iris)\n",
        "\n",
        "svm_clf_iris_noscaling = Pipeline([\n",
        "    (\"linear_svc\", LinearSVC(C=1, loss=\"hinge\", random_state=42, max_iter=10000))\n",
        "])\n",
        "svm_clf_iris_noscaling.fit(X_iris_train, y_iris_train)\n",
        "\n",
        "svm_clf_iris_scaling = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"linear_svc\", LinearSVC(C=1, loss=\"hinge\", random_state=42, max_iter=10000))\n",
        "])\n",
        "svm_clf_iris_scaling.fit(X_iris_train, y_iris_train)\n",
        "\n",
        "# Ocena\n",
        "y_iris_train_pred_noscaling = svm_clf_iris_noscaling.predict(X_iris_train)\n",
        "y_iris_train_pred_scaling  = svm_clf_iris_scaling.predict(X_iris_train)\n",
        "acc_iris_train_noscaling = accuracy_score(y_iris_train, y_iris_train_pred_noscaling)\n",
        "acc_iris_train_scaling   = accuracy_score(y_iris_train, y_iris_train_pred_scaling)\n",
        "\n",
        "y_iris_test_pred_noscaling = svm_clf_iris_noscaling.predict(X_iris_test)\n",
        "y_iris_test_pred_scaling  = svm_clf_iris_scaling.predict(X_iris_test)\n",
        "acc_iris_test_noscaling = accuracy_score(y_iris_test, y_iris_test_pred_noscaling)\n",
        "acc_iris_test_scaling   = accuracy_score(y_iris_test, y_iris_test_pred_scaling)\n",
        "\n",
        "print(\"Iris — accuracy:\")\n",
        "print(\"train (no scaling):\", acc_iris_train_noscaling)\n",
        "print(\"train (with scaling):\", acc_iris_train_scaling)\n",
        "print(\"test  (no scaling):\", acc_iris_test_noscaling)\n",
        "print(\"test  (with scaling):\", acc_iris_test_scaling)\n",
        "\n",
        "# Prosta wizualizacja (chmura punktów cech)\n",
        "plt.figure()\n",
        "plt.scatter(X_iris_train['petal width (cm)'], X_iris_train['petal length (cm)'])\n",
        "plt.xlabel(\"petal width (cm)\")\n",
        "plt.ylabel(\"petal length (cm)\")\n",
        "plt.title(\"Iris — dane treningowe (2 cechy)\")\n",
        "plt.show()\n",
        "\n",
        "# Zapis poprawnych wyników do iris_acc.pkl\n",
        "import pickle\n",
        "iris_results = (acc_iris_train_noscaling, acc_iris_test_noscaling, acc_iris_train_scaling, acc_iris_test_scaling)\n",
        "with open(\"iris_acc.pkl\", \"wb\") as f:\n",
        "    pickle.dump(iris_results, f)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3714062c",
      "metadata": {
        "id": "3714062c"
      },
      "source": [
        "## Sekcja 3 — Regresja: LinearSVR, PolynomialFeatures+LinearSVR, SVR(poly) + strojenie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1921f94",
      "metadata": {
        "id": "e1921f94"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
        "from sklearn.svm import LinearSVR, SVR\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "\n",
        "# Dane syntetyczne (nieliniowa zależność 4-go stopnia + szum)\n",
        "size = 900\n",
        "X_reg = np.random.rand(size) * 5 - 2.5\n",
        "w4, w3, w2, w1, w0 = 1, 2, 1, -4, 2\n",
        "y_reg = w4*(X_reg**4) + w3*(X_reg**3) + w2*(X_reg**2) + w1*X_reg + w0 + np.random.randn(size)*8 - 4\n",
        "\n",
        "df = pd.DataFrame({'x': X_reg, 'y': y_reg})\n",
        "df.plot.scatter(x='x', y='y')\n",
        "plt.title(\"Dane do regresji (syntetyczne)\")\n",
        "plt.show()\n",
        "\n",
        "X_reg_reshaped = X_reg.reshape(-1, 1)\n",
        "y_reg_reshaped = y_reg.reshape(-1, 1)\n",
        "\n",
        "# Podział danych\n",
        "X_reg_train, X_reg_test, y_reg_train, y_reg_test = train_test_split(X_reg_reshaped, y_reg_reshaped, random_state=42)\n",
        "\n",
        "# 1) LinearSVR bez ekspansji cech\n",
        "svm_linreg = LinearSVR(random_state=42, max_iter=10000)\n",
        "svm_linreg.fit(X_reg_train, y_reg_train.ravel())  # y jako 1D\n",
        "y_linreg_pred = svm_linreg.predict(X_reg_train)\n",
        "mse_linreg_svr_train = mean_squared_error(y_reg_train, y_linreg_pred)\n",
        "print(\"LinearSVR (bez ekspansji) — train MSE:\", mse_linreg_svr_train)\n",
        "\n",
        "plt.figure()\n",
        "plt.scatter(X_reg_train, y_reg_train)\n",
        "plt.scatter(X_reg_train, y_linreg_pred.reshape(-1, 1))\n",
        "plt.title(\"LinearSVR bez ekspansji cech\")\n",
        "plt.xlabel(\"X\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.show()\n",
        "\n",
        "# 2) Pipeline: PolynomialFeatures (stopień 4) + StandardScaler + LinearSVR\n",
        "model = Pipeline([\n",
        "    ('poly_features', PolynomialFeatures(degree=4)),\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('svr', LinearSVR(random_state=42, max_iter=10000))\n",
        "])\n",
        "model.fit(X_reg_train, y_reg_train.ravel())\n",
        "train_mse = mean_squared_error(y_reg_train, model.predict(X_reg_train))\n",
        "test_mse  = mean_squared_error(y_reg_test,  model.predict(X_reg_test))\n",
        "print(\"Poly(4)+LinearSVR — train MSE:\", train_mse)\n",
        "print(\"Poly(4)+LinearSVR — test  MSE:\",  test_mse)\n",
        "\n",
        "plt.figure()\n",
        "plt.scatter(X_reg_train, y_reg_train)\n",
        "plt.scatter(X_reg_train, model.predict(X_reg_train).reshape(-1, 1))\n",
        "plt.title(\"LinearSVR z ekspansją wielomianową (stopień 4)\")\n",
        "plt.xlabel(\"X\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.show()\n",
        "\n",
        "# 3) SVR z kernelem polynomial (stopień 4)\n",
        "svm_poly_reg = SVR(kernel=\"poly\", degree=4)\n",
        "svm_poly_reg.fit(X_reg_train, y_reg_train.ravel())\n",
        "y_reg_svr_pred = svm_poly_reg.predict(X_reg_train)\n",
        "\n",
        "plt.figure()\n",
        "plt.scatter(X_reg_train, y_reg_train)\n",
        "plt.scatter(X_reg_train, y_reg_svr_pred.reshape(-1, 1))\n",
        "plt.title(\"SVR(kernel='poly', degree=4) — bazowo\")\n",
        "plt.xlabel(\"X\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.show()\n",
        "\n",
        "mse_reg_svr_train = mean_squared_error(y_reg_train, y_reg_svr_pred)\n",
        "print(\"SVR poly — train MSE:\", mse_reg_svr_train)\n",
        "\n",
        "# 4) Strojenie hiperparametrów C i coef0 dla SVR(poly, degree=4)\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'coef0': [0.1, 1, 10]\n",
        "}\n",
        "search = GridSearchCV(SVR(kernel='poly', degree=4), param_grid, scoring='neg_mean_squared_error')\n",
        "search.fit(X_reg_train, y_reg_train.ravel())\n",
        "best_C = search.best_params_['C']\n",
        "best_coef0 = search.best_params_['coef0']\n",
        "print(\"Best C:\", best_C)\n",
        "print(\"Best coef0:\", best_coef0)\n",
        "\n",
        "model_3 = SVR(kernel='poly', degree=4, C=best_C, coef0=best_coef0)\n",
        "model_3.fit(X_reg_train, y_reg_train.ravel())\n",
        "train_mse_3 = mean_squared_error(y_reg_train, model_3.predict(X_reg_train))\n",
        "test_mse_3  = mean_squared_error(y_reg_test,  model_3.predict(X_reg_test))\n",
        "print(\"SVR poly (tuned) — train MSE:\", train_mse_3)\n",
        "print(\"SVR poly (tuned) — test  MSE:\",  test_mse_3)\n",
        "\n",
        "plt.figure()\n",
        "plt.scatter(X_reg_train, y_reg_train)\n",
        "plt.scatter(X_reg_train, model_3.predict(X_reg_train).reshape(-1, 1))\n",
        "plt.title(\"SVR(kernel='poly', degree=4) — po strojeniu parametrów\")\n",
        "plt.xlabel(\"X\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.show()\n",
        "\n",
        "# Zapis wyników regresji\n",
        "results = (train_mse, test_mse, train_mse_3, test_mse_3)\n",
        "with open(\"reg_mse.pkl\", \"wb\") as f:\n",
        "    pickle.dump(results, f)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}